{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REDSEA python version 0.0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edited from the original REDSEA python version 0.0.1 file in this folder (see that for details).\n",
    "\n",
    "Edited by Ben Caiello, with the intent of allowing it to work with current DeepCell segmentation masks / the steinbock pipeline. The algorithm is not identical, as that is not possible (I think) given the differenes in the masks of old DeepCell and new DeepCell (+ / - zero boundaries changes the effective pixel width of the boundary measurement step).\n",
    "\n",
    "Dataset I had been using for CD3 / CD20 compensation: https://zenodo.org/records/8023452\n",
    "\n",
    "Passed through steinbock to derive .tiffs and masks, then fed into this script\n",
    "\n",
    "The directory structure required for the script as-written is the one naturally produced by steinbock:\n",
    "\n",
    "A master directory with two folders: \\img & \\masks - each containing .tiffs with the original images and the DeepCell generated masks, repectively, with matching file names - and 1 .csv file (panel.csv). These are all naturally produced by steinbock when it is run.\n",
    "\n",
    "The script has not been thoroughly tested, but should produce outputs and seems to be doing what it is supposed to with the limited testing so far.\n",
    "\n",
    "\n",
    "Some (potential and certain) differences in the algorithm to note:\n",
    "    1. Since the masks format is different with DeepCell now (no cell-cell padding with 0's), the algorithm is made to find border px by looking for >1 segmentation label (indicating >1 cell or cell + background boundary)\n",
    "    2. Also, because of the lack of padding, the effective distances and sizes of the diamond / square boder px identification step is altered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package Imports\n",
    "import PIL\n",
    "from PIL import Image, ImageSequence, ImageOps\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage \n",
    "import skimage.measure\n",
    "import skimage.morphology\n",
    "import glob\n",
    "from scipy.io import loadmat\n",
    "import time\n",
    "\n",
    "import tifffile\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Edit these for your run!\n",
    "# file locations\n",
    "mainPath = 'C:\\\\Users\\\\caiello\\\\Desktop\\\\RedSEA practice\\\\practice' # main folder must contain \\img and \\masks folders and a panel.csv file (matching steinbock output)\n",
    "\n",
    "# for multiple images at once:\n",
    "file_list = []\n",
    "for i in os.listdir(mainPath + \"\\\\img\"):\n",
    "    i = i.replace(\".tiff\",\"\")\n",
    "    file_list.append(i)\n",
    "\n",
    "# or set file_name manually\n",
    "file_single = 'RNANeg_Tonsil_003'  #do not include the .tiff file type!\n",
    "\n",
    "#  select which channel to normalize\n",
    "normChannels = [13,18]    # I use numbers here, can switch to names as in your panel file -- if you set \"channel_names_numbers = False\" in the the file_reader call in the next cell \n",
    "\n",
    "# parameters for compensation (change as desired)\n",
    "REDSEAChecker = 1 # 1 means subtract+ reinforce\n",
    "elementShape = 1 # star, 1 == square size\n",
    "elementSize = 1 # star or square extension size\n",
    "\n",
    "\n",
    "# output path\n",
    "pathResults = mainPath + '/intensities' # output location, set as intensities here to match steinbock output\n",
    "try:\n",
    "    os.listdir(pathResults)\n",
    "except:\n",
    "    os.mkdir(pathResults)\n",
    "\n",
    "alt_path = \"\\\\an\\\\alternate\\folder\\\\in\\\\which\\\\to\\\\put\\\\your\\\\non-scaled\\\\and\\\\non-compensated\\\\data\" ## use if you want the non-compensated / non-scaled data, but don't want them crowding the main steinbock intensities folder\n",
    "######### if you use alt_path, manually make the directory in file explorer!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Functions (normally, minimize this cell)\n",
    "# helper function 1\n",
    "def ismember(a, b):\n",
    "    bind = {}\n",
    "    for i, elt in enumerate(b):\n",
    "        if elt not in bind:\n",
    "            bind[elt] = i\n",
    "    return [bind.get(itm, None) for itm in a]  # None can be replaced by any other \"not in b\" value\n",
    "\n",
    "# helper function 2\n",
    "\n",
    "def printProgressBar (iteration, total, prefix = '', suffix = '', decimals = 1, length = 100, fill = '█', printEnd = \"\\r\"):\n",
    "    percent = (\"{0:.\" + str(decimals) + \"f}\").format(100 * (iteration / float(total)))\n",
    "    filledLength = int(length * iteration // total)\n",
    "    bar = fill * filledLength + '-' * (length - filledLength)\n",
    "    print(f'\\r{prefix} |{bar}| {percent}% {suffix}', end = printEnd)\n",
    "    # Print New Line on Complete\n",
    "    if iteration == total: \n",
    "        print()\n",
    "        \n",
    "def file_reader(mainPath,file_name,channel_names_numbers = True):\n",
    "    massDS_path = mainPath + '\\\\panel.csv' # csv file location, need\n",
    "    pathTiff = mainPath + '\\\\img\\\\' + file_name + '.tiff' #  tiff location, links to a single .tiff\n",
    "    pathMat = mainPath + '\\\\masks\\\\' + file_name + '.tiff' # corresponding .tiff's mask\n",
    "        \n",
    "    ####### Read in of files:\n",
    "    ### read in panel.csv\n",
    "    massDS = pd.read_csv(massDS_path) # read the mass csv\n",
    "    if channel_names_numbers == True:\n",
    "        clusterChannels = massDS[massDS['keep'] == 1].reset_index().index.values # only get the label column minus 1 is for zero-indexing (matched channel numbers with Napari)\n",
    "                                                # remove -1 if you want 1-indexing of the channel names\n",
    "    else:\n",
    "        clusterChannels = massDS['name']  # if you want your channel names to be want is used\n",
    "    channelNum = len(clusterChannels) # how many channels\n",
    "    #print(massDS.head())\n",
    "    \n",
    "    #### this part reads in multichannel tiff file\n",
    "    # read in the image and transform into a 'countsNoNoise' matrix\n",
    "    array_list=[]\n",
    "    for channel in clusterChannels:\n",
    "        t=tifffile.imread(pathTiff)[channel]\n",
    "        array_list.append(t)\n",
    "    countsNoNoise=np.stack(array_list,axis=2) # count matrices in the image\n",
    "    \n",
    "    ###### Read in segmentation .tiff\n",
    "        # Define the boundary region\n",
    "        #### these code is just entire translation of redsea matlab v1.0\n",
    "    Segmentation = tifffile.imread(pathMat).astype('int')\n",
    "    cellNum = np.max(Segmentation) # how many labels\n",
    "    stats = skimage.measure.regionprops(Segmentation+1) # get the regional props for all the labels\n",
    "\n",
    "    ### make empty container matrices\n",
    "    data = np.zeros((cellNum + 1,channelNum))\n",
    "    dataScaleSize = np.zeros((cellNum + 1,channelNum))\n",
    "    cellSizes = np.zeros((cellNum + 1,1))\n",
    "    \n",
    "    # this part extract counts data from the whole cell regions, for each individual cells etc\n",
    "    \n",
    "    for i in range(cellNum + 1): # for each cell (label)\n",
    "        label_counts=[countsNoNoise[coord[0],coord[1],:] for coord in stats[i].coords] # all channel count for this cell\n",
    "        data[i,0:channelNum] = np.sum(label_counts, axis=0) #  sum the counts for this cell\n",
    "        dataScaleSize[i,0:channelNum] = np.sum(label_counts, axis=0) / stats[i].area # scaled by size\n",
    "        cellSizes[i] = stats[i].area # cell sizes\n",
    "\n",
    "    return clusterChannels, countsNoNoise, Segmentation, cellNum, channelNum, data, cellSizes, dataScaleSize\n",
    "\n",
    "def cell_cell_matrix(Segmentation, cellNum, REDSEAChecker = REDSEAChecker):\n",
    "    # this block is for computing cell cell matrix\n",
    "    [rowNum, colNum] = Segmentation.shape\n",
    "    cellPairMap = np.zeros(((cellNum + 1),(cellNum + 1))) # cell-cell shared perimeter matrix container\n",
    "    \n",
    "    # start looping the mask and produce the cell-cell contact matrix\n",
    "    for i in range(rowNum):\n",
    "        if i == 0:   # these conditional statements account for pixels on the edge of the image by shrinking the 3x3 box to smaller dimensions\n",
    "            a = 0\n",
    "            c = 2\n",
    "        elif i == (rowNum - 1):\n",
    "            a = 1\n",
    "            c = 1\n",
    "        else:\n",
    "            a = 1\n",
    "            c = 2\n",
    "        for j in range(colNum):\n",
    "            if j == 0:\n",
    "                b = 0\n",
    "                d = 2\n",
    "            elif j == (colNum - 1):\n",
    "                b = 1\n",
    "                d = 1\n",
    "            else:\n",
    "                b = 1\n",
    "                d = 2\n",
    "            tempMatrix = Segmentation[i-a:i+c,j-b:j+d] # the 3x3 window, centered on the point i,j\n",
    "            #print(tempMatrix)\n",
    "            tempFactors = np.unique(tempMatrix).astype('int') #unique\n",
    "            #print(tempFactors)\n",
    "            centerpoint_value = Segmentation[i,j]\n",
    "            #print(centerpoint_value)\n",
    "            for k in tempFactors:\n",
    "                if k != centerpoint_value: # only add to the cellPairMap for the centerpoint pixel -- this prevents multiplicate counting\n",
    "                    #print(\"trigger\")\n",
    "                    cellPairMap[centerpoint_value,k] = cellPairMap[centerpoint_value,k] + 1  \n",
    "        \n",
    "    # converting the cell cell maps to fraction of cell - cell boundary (not of total cell boundary [!?] -- as in boundary with empty space not counted)\n",
    "    cellPairNorm = np.zeros(((cellNum+1),(cellNum+1)))\n",
    "    for i in np.arange(0,len(cellPairMap)):\n",
    "        if np.sum(cellPairMap[i]) > 0:\n",
    "            cellPairNorm[i] = - (cellPairMap[i] / np.sum(cellPairMap[i]))\n",
    "        #else:\n",
    "            #print(\"this shouldn't happen\")\n",
    "    cellPairNorm = cellPairNorm[1:,1:]\n",
    "    cellPairNorm = cellPairNorm + REDSEAChecker*np.identity(cellNum ) \n",
    "    #display(pd.DataFrame(cellPairMap))\n",
    "    print(pd.DataFrame(cellPairMap).sum())\n",
    "    return cellPairNorm, rowNum, colNum\n",
    "\n",
    "def Cell_Edge_Intensities(Segmentation, cellNum, channelNum, countsNoNoise, rowNum, colNum, elementShape = 2, elementSize = 2):\n",
    "    MIBIdataNearEdge1 = np.zeros((cellNum+1,channelNum))\n",
    "\n",
    "    ##### A List of Items\n",
    "    items = list(range(cellNum + 1))\n",
    "    l = len(items)\n",
    "    printProgressBar(0, l, prefix = 'Progress:', suffix = 'Complete', length = 50) # progress bar\n",
    "    #####\n",
    "    \n",
    "    ######pre-calculated shape\n",
    "    if elementShape==1: # square\n",
    "        shape=skimage.morphology.square((2*elementSize) + 1)\n",
    "    elif elementShape==2: # diamond\n",
    "        shape=skimage.morphology.diamond(elementSize) # create diamond shapte based on elementSize\n",
    "    else:\n",
    "        print(\"Error elementShape Value not recognized.\")\n",
    "    ############\n",
    "    \n",
    "    \n",
    "    for i in range(cellNum + 1) :\n",
    "        if i == 0:\n",
    "            continue\n",
    "        [tempRow,tempCol] = np.asarray(Segmentation==i).nonzero()\n",
    "        [rowNum, colNum] = Segmentation.shape\n",
    "        # sequence in row not col, should not affect the code\n",
    "        for j in range(len(tempRow)):\n",
    "            label_in_shape=[] # empty list in case\n",
    "            if (tempRow[j] - elementSize) <= -1:\n",
    "                a = 0 + tempRow[j]\n",
    "                c = 1 + elementSize\n",
    "            elif (tempRow[j] + elementSize) > rowNum - 1:\n",
    "                a = 0 + elementSize\n",
    "                c = 1 + rowNum - tempCol[j]\n",
    "            else:\n",
    "                a = 0 + elementSize\n",
    "                c = 1 + elementSize\n",
    "            if (tempCol[j] - elementSize) <= -1:\n",
    "                b = 0 + tempCol[j]\n",
    "                d = 1 + elementSize\n",
    "            elif (tempCol[j] + elementSize) > colNum - 1:\n",
    "                b = 0 + elementSize\n",
    "                d = 1 + colNum - tempCol[j]\n",
    "            else:\n",
    "                b = 0 + elementSize\n",
    "                d = 1 + elementSize\n",
    "            tempMatrix = Segmentation[tempRow[j]-a:tempRow[j]+c,tempCol[j]-b:tempCol[j]+d] # the 3x3 window, centered on the point i,j\n",
    "            [dim1, dim2] = tempMatrix.shape\n",
    "            reducedShape = shape[:dim1,:dim2].astype('bool')\n",
    "            reducedMatrix = tempMatrix[reducedShape]   # the reduced shape /  matrix lines are there to accommodate the diamond shape\n",
    "            tempFactors = np.unique(reducedMatrix).astype('int')\n",
    "            if len(tempFactors) > 1:\n",
    "                MIBIdataNearEdge1[i,:] = MIBIdataNearEdge1[i,:] + countsNoNoise[tempRow[j],tempCol[j],:]\n",
    "            # Update Progress Bar\n",
    "            if ((i % 500) == 0) or (i == (cellNum - 1)):\n",
    "                printProgressBar(i + 1, l, prefix = 'Progress:', suffix = 'Complete', length = 50)\n",
    "            return MIBIdataNearEdge1\n",
    "            \n",
    "def CalculateREDSEA(MIBIdataNearEdge1, cellPairNorm, data, channelNormIdentity, cellNum, dataScaleSize, cellSizes):    \n",
    "    MIBIdataNorm2 = np.transpose(np.dot(np.transpose(MIBIdataNearEdge1[1:,:]),cellPairNorm))\n",
    "    #this is boundary signal subtracted by cell neighbor boundary\n",
    "    MIBIdataNorm2 = MIBIdataNorm2 + data[1:,:] # reinforce onto the whole cell signal (original signal)\n",
    "    \n",
    "    MIBIdataNorm2[MIBIdataNorm2<0] = 0 # clear out the negative ones\n",
    "    # flip the channelNormIdentity for calculation\n",
    "    rev_channelNormIdentity=np.ones_like(channelNormIdentity)-channelNormIdentity\n",
    "    # composite the normalized channels with non-normalized channels\n",
    "    # MIBIdataNorm2 is the matrix to return\n",
    "    MIBIdataNorm2 = data[1:,:] * np.transpose(np.tile(rev_channelNormIdentity,(1,cellNum))) + MIBIdataNorm2 * np.transpose(np.tile(channelNormIdentity,(1,cellNum)))\n",
    "    \n",
    "    # the function should return 4 variables\n",
    "    dataCells = data[1:,:]\n",
    "    dataScaleSizeCells = dataScaleSize[1:,:]\n",
    "    dataCompenCells = MIBIdataNorm2\n",
    "    dataCompenScaleSizeCells = MIBIdataNorm2 / cellSizes[1:,:]\n",
    "\n",
    "    return dataCells, dataScaleSizeCells, dataCompenCells, dataCompenScaleSizeCells\n",
    "\n",
    "def data_matrix_with_label_and_cellsizes(data_in, cellNum, cellSizes, clusterChannels):\n",
    "    ### in a separate funcito because this data is not likely to be wanted. still it can be accessed:\n",
    "    labelVec = [i for i in np.arange(1,cellNum + 1,1)]\n",
    "    cellSizesVec_flat = [item for sublist in cellSizes[1:,:] for item in sublist] # flat the list\n",
    "    dataL = pd.DataFrame({'Object':labelVec, 'cell_size':cellSizesVec_flat})\n",
    "    dataCells_df=pd.DataFrame(data_in)\n",
    "    dataCells_df.columns = clusterChannels\n",
    "    data_out = pd.concat((dataL,dataCells_df),axis=1)\n",
    "    return data_out\n",
    "\n",
    "def Outputter(data_in, file_name, pathResults = pathResults):\n",
    "    data_in.to_csv(pathResults + '\\\\' + file_name + \".csv\", index = False)\n",
    "\n",
    "def RunRedSEA(mainPath, file, channel_names_numbers = True, pathResults = pathResults, alt_path = pathResults, normChannels = normChannels, print_options = \"only_compensated_and_scaled\"):\n",
    "    if print_options not in ['only_compensated_and_scaled','only_scaled','all']:\n",
    "        raise(\"Error: print_options not one of the following: 'only_compensated_and_scaled', 'only_scaled', or 'all'!\") \n",
    "    if type(file) == list:\n",
    "        for ii in file:\n",
    "            file_name = ii\n",
    "            print(\"Starting RedSEA compensation of file: \" + file_name)\n",
    "            clusterChannels, countsNoNoise, Segmentation, cellNum, channelNum, data, cellSizes, dataScaleSize = file_reader(mainPath, ii, channel_names_numbers = channel_names_numbers)\n",
    "            normChannelsInds = ismember(normChannels,clusterChannels)\n",
    "            channelNormIdentity = np.zeros((len(clusterChannels),1))\n",
    "            # make a flag for compensation\n",
    "            for i in range(len(normChannelsInds)):\n",
    "                    channelNormIdentity[normChannelsInds[i]] = 1 \n",
    "            # print(\"cellNum for \" + file_name + \" \" + str(cellNum))\n",
    "            cellPairNorm, rowNum, colNum = cell_cell_matrix(Segmentation = Segmentation, REDSEAChecker = REDSEAChecker, cellNum = cellNum)\n",
    "            MIBIdataNearEdge1 = Cell_Edge_Intensities(Segmentation, countsNoNoise = countsNoNoise, cellNum = cellNum, channelNum = channelNum, rowNum = rowNum, colNum = colNum, elementShape = 2, elementSize = 2)\n",
    "            dataCells, dataScaleSizeCells, dataCompenCells, dataCompenScaleSizeCells = CalculateREDSEA(MIBIdataNearEdge1 = MIBIdataNearEdge1, cellPairNorm = cellPairNorm, data = data, channelNormIdentity = channelNormIdentity, cellNum = cellNum, dataScaleSize = dataScaleSize, cellSizes = cellSizes)\n",
    "            dataL_full = data_matrix_with_label_and_cellsizes(dataCells, cellNum = cellNum, cellSizes = cellSizes, clusterChannels = clusterChannels)\n",
    "            dataScaleSizeL_full = data_matrix_with_label_and_cellsizes(dataScaleSizeCells, cellNum = cellNum, cellSizes = cellSizes, clusterChannels = clusterChannels)\n",
    "            dataCompenL_full = data_matrix_with_label_and_cellsizes(dataCompenCells, cellNum = cellNum, cellSizes = cellSizes, clusterChannels = clusterChannels)\n",
    "            dataCompenScaleSizeL_full = data_matrix_with_label_and_cellsizes(dataCompenScaleSizeCells, cellNum = cellNum, cellSizes = cellSizes, clusterChannels = clusterChannels)\n",
    "            if print_options == \"only_compensated_and_scaled\":\n",
    "                Outputter(dataCompenScaleSizeL_full, file_name = file_name)\n",
    "            elif print_options == \"only_scaled\":\n",
    "                Outputter(dataCompenScaleSizeL_full, file_name = file_name)\n",
    "                Outputter(dataScaleSizeL_full, file_name = file_name + \"_pre_REDSEA.csv\", pathResults = alt_path)\n",
    "            elif print_options == \"all\":\n",
    "                Outputter(dataL_full, file_name = file_name + \"_pre_REDSEA_unscaled.csv\")\n",
    "                Outputter(dataScaleSizeL_full, file_name = file_name + \"_pre_REDSEA_scaled.csv\")\n",
    "                Outputter(dataCompenL_full, file_name = file_name + \"_post_REDSEA_unscaled.csv\")\n",
    "                Outputter(dataCompenScaleSizeL_full, file_name = file_name)\n",
    "    elif type(file) == str:\n",
    "        file_name = file\n",
    "        print(\"Starting RedSEA compensation of file: \" + file_name)\n",
    "        clusterChannels, countsNoNoise, Segmentation, cellNum, channelNum, data, cellSizes, dataScaleSize = file_reader(mainPath, file_name, channel_names_numbers = channel_names_numbers)\n",
    "        normChannelsInds = ismember(normChannels,clusterChannels)\n",
    "        channelNormIdentity = np.zeros((len(clusterChannels),1))\n",
    "        # make a flag for compensation\n",
    "        for i in range(len(normChannelsInds)):\n",
    "                channelNormIdentity[normChannelsInds[i]] = 1 \n",
    "        # print(\"cellNum for \" + file_name + \" \" + str(cellNum))\n",
    "        cellPairNorm, rowNum, colNum = cell_cell_matrix(Segmentation = Segmentation, REDSEAChecker = REDSEAChecker, cellNum = cellNum)\n",
    "        MIBIdataNearEdge1 = Cell_Edge_Intensities(Segmentation, countsNoNoise = countsNoNoise, cellNum = cellNum, channelNum = channelNum, rowNum = rowNum, colNum = colNum, elementShape = 2, elementSize = 2)\n",
    "        dataCells, dataScaleSizeCells, dataCompenCells, dataCompenScaleSizeCells = CalculateREDSEA(MIBIdataNearEdge1 = MIBIdataNearEdge1, cellPairNorm = cellPairNorm, data = data, channelNormIdentity = channelNormIdentity, cellNum = cellNum, dataScaleSize = dataScaleSize, cellSizes = cellSizes)\n",
    "        dataL_full = data_matrix_with_label_and_cellsizes(dataCells, cellNum = cellNum, cellSizes = cellSizes, clusterChannels = clusterChannels)\n",
    "        dataScaleSizeL_full = data_matrix_with_label_and_cellsizes(dataScaleSizeCells, cellNum = cellNum, cellSizes = cellSizes, clusterChannels = clusterChannels)\n",
    "        dataCompenL_full = data_matrix_with_label_and_cellsizes(dataCompenCells, cellNum = cellNum, cellSizes = cellSizes, clusterChannels = clusterChannels)\n",
    "        dataCompenScaleSizeL_full = data_matrix_with_label_and_cellsizes(dataCompenScaleSizeCells, cellNum = cellNum, cellSizes = cellSizes, clusterChannels = clusterChannels)\n",
    "        if print_options == \"only_compensated_and_scaled\":\n",
    "            Outputter(dataCompenScaleSizeL_full, file_name = file_name)\n",
    "        elif print_options == \"only_scaled\":\n",
    "            Outputter(dataCompenScaleSizeL_full, file_name = file_name)\n",
    "            Outputter(dataScaleSizeL_full, file_name = file_name + \"_pre_REDSEA.csv\", pathResults = alt_path)\n",
    "        elif print_options == \"all\":\n",
    "            Outputter(dataL_full, file_name = file_name + \"_pre_REDSEA_unscaled.csv\")\n",
    "            Outputter(dataScaleSizeL_full, file_name = file_name + \"_pre_REDSEA_scaled.csv\")\n",
    "            Outputter(dataCompenL_full, file_name = file_name + \"_post_REDSEA_unscaled.csv\")\n",
    "            Outputter(dataCompenScaleSizeL_full, file_name = file_name)\n",
    "    return dataL_full, dataScaleSizeL_full, dataCompenL_full, dataCompenScaleSizeL_full # these are the files of only the last file, if running multiple files at once\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting RedSEA compensation of file: RNANeg_Tonsil_001\n",
      "0       107225.0\n",
      "1            9.0\n",
      "2           24.0\n",
      "3           20.0\n",
      "4           22.0\n",
      "          ...   \n",
      "7713        13.0\n",
      "7714        13.0\n",
      "7715        11.0\n",
      "7716        13.0\n",
      "7717         9.0\n",
      "Length: 7718, dtype: float64\n",
      "Starting RedSEA compensation of file: RNANeg_Tonsil_002------| 0.0% Complete\n",
      "0        55651.0\n",
      "1           11.0\n",
      "2           14.0\n",
      "3           16.0\n",
      "4           12.0\n",
      "          ...   \n",
      "20905       44.0\n",
      "20906       13.0\n",
      "20907        9.0\n",
      "20908       16.0\n",
      "20909        9.0\n",
      "Length: 20910, dtype: float64\n",
      "Starting RedSEA compensation of file: RNANeg_Tonsil_003------| 0.0% Complete\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[96], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Whole folder run (this one had 4 files in it):\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m dataL_full, dataScaleSizeL_full, dataCompenL_full, dataCompenScaleSizeL_full \u001b[38;5;241m=\u001b[39m \u001b[43mRunRedSEA\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmainPath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmainPath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfile_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannel_names_numbers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormChannels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnormChannels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_options\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43monly_scaled\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[95], line 214\u001b[0m, in \u001b[0;36mRunRedSEA\u001b[1;34m(mainPath, file, channel_names_numbers, pathResults, alt_path, normChannels, print_options)\u001b[0m\n\u001b[0;32m    212\u001b[0m file_name \u001b[38;5;241m=\u001b[39m ii\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting RedSEA compensation of file: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m file_name)\n\u001b[1;32m--> 214\u001b[0m clusterChannels, countsNoNoise, Segmentation, cellNum, channelNum, data, cellSizes, dataScaleSize \u001b[38;5;241m=\u001b[39m \u001b[43mfile_reader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmainPath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mii\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannel_names_numbers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mchannel_names_numbers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    215\u001b[0m normChannelsInds \u001b[38;5;241m=\u001b[39m ismember(normChannels,clusterChannels)\n\u001b[0;32m    216\u001b[0m channelNormIdentity \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mlen\u001b[39m(clusterChannels),\u001b[38;5;241m1\u001b[39m))\n",
      "Cell \u001b[1;32mIn[95], line 41\u001b[0m, in \u001b[0;36mfile_reader\u001b[1;34m(mainPath, file_name, channel_names_numbers)\u001b[0m\n\u001b[0;32m     39\u001b[0m array_list\u001b[38;5;241m=\u001b[39m[]\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m channel \u001b[38;5;129;01min\u001b[39;00m clusterChannels:\n\u001b[1;32m---> 41\u001b[0m     t\u001b[38;5;241m=\u001b[39m\u001b[43mtifffile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpathTiff\u001b[49m\u001b[43m)\u001b[49m[channel]\n\u001b[0;32m     42\u001b[0m     array_list\u001b[38;5;241m.\u001b[39mappend(t)\n\u001b[0;32m     43\u001b[0m countsNoNoise\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mstack(array_list,axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m) \u001b[38;5;66;03m# count matrices in the image\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tifffile\\tifffile.py:1062\u001b[0m, in \u001b[0;36mimread\u001b[1;34m(files, aszarr, key, series, level, squeeze, maxworkers, mode, name, offset, size, pattern, axesorder, categories, imread, sort, container, chunkshape, dtype, axestiled, ioworkers, chunkmode, fillvalue, zattrs, multiscales, omexml, out, out_inplace, _multifile, _useframes, **kwargs)\u001b[0m\n\u001b[0;32m   1057\u001b[0m     files \u001b[38;5;241m=\u001b[39m files[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1059\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(files, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m   1060\u001b[0m     files, collections\u001b[38;5;241m.\u001b[39mabc\u001b[38;5;241m.\u001b[39mSequence\n\u001b[0;32m   1061\u001b[0m ):\n\u001b[1;32m-> 1062\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mTiffFile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1063\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1064\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1065\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1066\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1067\u001b[0m \u001b[43m        \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1068\u001b[0m \u001b[43m        \u001b[49m\u001b[43momexml\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43momexml\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1069\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_multifile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_multifile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1070\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_useframes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_useframes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1071\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mis_flags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1072\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m tif:\n\u001b[0;32m   1073\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m aszarr:\n\u001b[0;32m   1074\u001b[0m             \u001b[38;5;28;01massert\u001b[39;00m key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tifffile\\tifffile.py:3993\u001b[0m, in \u001b[0;36mTiffFile.__init__\u001b[1;34m(self, file, mode, name, offset, size, omexml, _multifile, _useframes, _parent, **is_flags)\u001b[0m\n\u001b[0;32m   3990\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+b\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m   3991\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minvalid mode \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmode\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 3993\u001b[0m fh \u001b[38;5;241m=\u001b[39m \u001b[43mFileHandle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3994\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fh \u001b[38;5;241m=\u001b[39m fh\n\u001b[0;32m   3995\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multifile \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m _multifile \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(_multifile)\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tifffile\\tifffile.py:13929\u001b[0m, in \u001b[0;36mFileHandle.__init__\u001b[1;34m(self, file, mode, name, offset, size)\u001b[0m\n\u001b[0;32m  13927\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m  13928\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock \u001b[38;5;241m=\u001b[39m NullContext()\n\u001b[1;32m> 13929\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m  13930\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fh \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\Lib\\site-packages\\tifffile\\tifffile.py:13942\u001b[0m, in \u001b[0;36mFileHandle.open\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m  13938\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mfspath(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file)\n\u001b[0;32m  13940\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m  13941\u001b[0m     \u001b[38;5;66;03m# file name\u001b[39;00m\n\u001b[1;32m> 13942\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrealpath\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m  13943\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dir, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file)\n\u001b[0;32m  13944\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fh \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "File \u001b[1;32m<frozen ntpath>:696\u001b[0m, in \u001b[0;36mrealpath\u001b[1;34m(path, strict)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Whole folder run (this one had 4 files in it):\n",
    "dataL_full, dataScaleSizeL_full, dataCompenL_full, dataCompenScaleSizeL_full = RunRedSEA(mainPath = mainPath, file = file_list, channel_names_numbers = True, normChannels = normChannels, print_options = \"only_scaled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Object</th>\n",
       "      <th>cell_size</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>4.926793</td>\n",
       "      <td>0.788452</td>\n",
       "      <td>0.661649</td>\n",
       "      <td>0.652807</td>\n",
       "      <td>0.269625</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.849422</td>\n",
       "      <td>...</td>\n",
       "      <td>0.345111</td>\n",
       "      <td>20.375765</td>\n",
       "      <td>8.192933</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.156391</td>\n",
       "      <td>4.087760</td>\n",
       "      <td>6.344390</td>\n",
       "      <td>2.887861</td>\n",
       "      <td>21.861406</td>\n",
       "      <td>1.737484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.159876</td>\n",
       "      <td>3.469197</td>\n",
       "      <td>2.454025</td>\n",
       "      <td>1.094108</td>\n",
       "      <td>0.722595</td>\n",
       "      <td>0.739134</td>\n",
       "      <td>0.179178</td>\n",
       "      <td>1.805447</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>2.221802</td>\n",
       "      <td>4.049692</td>\n",
       "      <td>0.232816</td>\n",
       "      <td>0.278882</td>\n",
       "      <td>5.062777</td>\n",
       "      <td>9.115035</td>\n",
       "      <td>4.463692</td>\n",
       "      <td>23.167364</td>\n",
       "      <td>1.955778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.255748</td>\n",
       "      <td>1.553636</td>\n",
       "      <td>1.000429</td>\n",
       "      <td>0.605723</td>\n",
       "      <td>0.510202</td>\n",
       "      <td>0.094054</td>\n",
       "      <td>1.764787</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151094</td>\n",
       "      <td>2.385300</td>\n",
       "      <td>9.332050</td>\n",
       "      <td>0.307272</td>\n",
       "      <td>0.224216</td>\n",
       "      <td>6.079697</td>\n",
       "      <td>13.259372</td>\n",
       "      <td>1.697419</td>\n",
       "      <td>13.507796</td>\n",
       "      <td>1.804346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.112569</td>\n",
       "      <td>1.680611</td>\n",
       "      <td>1.273399</td>\n",
       "      <td>1.319794</td>\n",
       "      <td>0.470234</td>\n",
       "      <td>0.688838</td>\n",
       "      <td>0.289421</td>\n",
       "      <td>1.556288</td>\n",
       "      <td>...</td>\n",
       "      <td>0.418586</td>\n",
       "      <td>27.638899</td>\n",
       "      <td>2.014158</td>\n",
       "      <td>0.153056</td>\n",
       "      <td>0.243548</td>\n",
       "      <td>5.158520</td>\n",
       "      <td>9.989205</td>\n",
       "      <td>1.534308</td>\n",
       "      <td>10.946206</td>\n",
       "      <td>1.715446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.658532</td>\n",
       "      <td>1.813758</td>\n",
       "      <td>0.810043</td>\n",
       "      <td>0.331333</td>\n",
       "      <td>0.707729</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>1.580072</td>\n",
       "      <td>...</td>\n",
       "      <td>0.394834</td>\n",
       "      <td>4.231170</td>\n",
       "      <td>1.833733</td>\n",
       "      <td>0.121115</td>\n",
       "      <td>0.110704</td>\n",
       "      <td>5.336914</td>\n",
       "      <td>9.130732</td>\n",
       "      <td>2.396150</td>\n",
       "      <td>35.118828</td>\n",
       "      <td>1.554082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Object  cell_size         0         1         2         3         4  \\\n",
       "0       1       16.0  0.062500  4.926793  0.788452  0.661649  0.652807   \n",
       "1       2       14.0  0.159876  3.469197  2.454025  1.094108  0.722595   \n",
       "2       3       25.0  0.000000  3.255748  1.553636  1.000429  0.605723   \n",
       "3       4       30.0  0.112569  1.680611  1.273399  1.319794  0.470234   \n",
       "4       5       22.0  0.000000  0.658532  1.813758  0.810043  0.331333   \n",
       "\n",
       "          5         6         7  ...        16         17        18        19  \\\n",
       "0  0.269625  0.062500  0.849422  ...  0.345111  20.375765  8.192933  0.062500   \n",
       "1  0.739134  0.179178  1.805447  ...  0.142857   2.221802  4.049692  0.232816   \n",
       "2  0.510202  0.094054  1.764787  ...  0.151094   2.385300  9.332050  0.307272   \n",
       "3  0.688838  0.289421  1.556288  ...  0.418586  27.638899  2.014158  0.153056   \n",
       "4  0.707729  0.136364  1.580072  ...  0.394834   4.231170  1.833733  0.121115   \n",
       "\n",
       "         20        21         22        23         24        25  \n",
       "0  0.156391  4.087760   6.344390  2.887861  21.861406  1.737484  \n",
       "1  0.278882  5.062777   9.115035  4.463692  23.167364  1.955778  \n",
       "2  0.224216  6.079697  13.259372  1.697419  13.507796  1.804346  \n",
       "3  0.243548  5.158520   9.989205  1.534308  10.946206  1.715446  \n",
       "4  0.110704  5.336914   9.130732  2.396150  35.118828  1.554082  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pre-comp data from the last file in the run, scaled by cell size\n",
    "dataScaleSizeL_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Object</th>\n",
       "      <th>cell_size</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>4.926793</td>\n",
       "      <td>0.788452</td>\n",
       "      <td>0.661649</td>\n",
       "      <td>0.652807</td>\n",
       "      <td>0.269625</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.849422</td>\n",
       "      <td>...</td>\n",
       "      <td>0.345111</td>\n",
       "      <td>20.375765</td>\n",
       "      <td>5.623331</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.156391</td>\n",
       "      <td>4.087760</td>\n",
       "      <td>6.344390</td>\n",
       "      <td>2.887861</td>\n",
       "      <td>21.861406</td>\n",
       "      <td>1.737484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.159876</td>\n",
       "      <td>3.469197</td>\n",
       "      <td>2.454025</td>\n",
       "      <td>1.094108</td>\n",
       "      <td>0.722595</td>\n",
       "      <td>0.739134</td>\n",
       "      <td>0.179178</td>\n",
       "      <td>1.805447</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>2.221803</td>\n",
       "      <td>1.850488</td>\n",
       "      <td>0.232816</td>\n",
       "      <td>0.278882</td>\n",
       "      <td>5.062777</td>\n",
       "      <td>9.115035</td>\n",
       "      <td>4.463692</td>\n",
       "      <td>23.167365</td>\n",
       "      <td>1.955779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.255748</td>\n",
       "      <td>1.553636</td>\n",
       "      <td>1.000429</td>\n",
       "      <td>0.605723</td>\n",
       "      <td>0.510202</td>\n",
       "      <td>0.094054</td>\n",
       "      <td>1.764787</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151094</td>\n",
       "      <td>2.385300</td>\n",
       "      <td>8.985885</td>\n",
       "      <td>0.307272</td>\n",
       "      <td>0.224216</td>\n",
       "      <td>6.079697</td>\n",
       "      <td>13.259371</td>\n",
       "      <td>1.697419</td>\n",
       "      <td>13.507797</td>\n",
       "      <td>1.804346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.112569</td>\n",
       "      <td>1.680611</td>\n",
       "      <td>1.273399</td>\n",
       "      <td>1.319794</td>\n",
       "      <td>0.470234</td>\n",
       "      <td>0.688838</td>\n",
       "      <td>0.289421</td>\n",
       "      <td>1.556288</td>\n",
       "      <td>...</td>\n",
       "      <td>0.418586</td>\n",
       "      <td>27.638900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.153056</td>\n",
       "      <td>0.243548</td>\n",
       "      <td>5.158520</td>\n",
       "      <td>9.989205</td>\n",
       "      <td>1.534308</td>\n",
       "      <td>10.946206</td>\n",
       "      <td>1.715446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.658532</td>\n",
       "      <td>1.813759</td>\n",
       "      <td>0.810043</td>\n",
       "      <td>0.331333</td>\n",
       "      <td>0.707729</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>1.580072</td>\n",
       "      <td>...</td>\n",
       "      <td>0.394834</td>\n",
       "      <td>4.231170</td>\n",
       "      <td>1.869282</td>\n",
       "      <td>0.121115</td>\n",
       "      <td>0.110704</td>\n",
       "      <td>5.336914</td>\n",
       "      <td>9.130732</td>\n",
       "      <td>2.396150</td>\n",
       "      <td>35.118827</td>\n",
       "      <td>1.554082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Object  cell_size         0         1         2         3         4  \\\n",
       "0       1       16.0  0.062500  4.926793  0.788452  0.661649  0.652807   \n",
       "1       2       14.0  0.159876  3.469197  2.454025  1.094108  0.722595   \n",
       "2       3       25.0  0.000000  3.255748  1.553636  1.000429  0.605723   \n",
       "3       4       30.0  0.112569  1.680611  1.273399  1.319794  0.470234   \n",
       "4       5       22.0  0.000000  0.658532  1.813759  0.810043  0.331333   \n",
       "\n",
       "          5         6         7  ...        16         17        18        19  \\\n",
       "0  0.269625  0.062500  0.849422  ...  0.345111  20.375765  5.623331  0.062500   \n",
       "1  0.739134  0.179178  1.805447  ...  0.142857   2.221803  1.850488  0.232816   \n",
       "2  0.510202  0.094054  1.764787  ...  0.151094   2.385300  8.985885  0.307272   \n",
       "3  0.688838  0.289421  1.556288  ...  0.418586  27.638900  0.000000  0.153056   \n",
       "4  0.707729  0.136364  1.580072  ...  0.394834   4.231170  1.869282  0.121115   \n",
       "\n",
       "         20        21         22        23         24        25  \n",
       "0  0.156391  4.087760   6.344390  2.887861  21.861406  1.737484  \n",
       "1  0.278882  5.062777   9.115035  4.463692  23.167365  1.955779  \n",
       "2  0.224216  6.079697  13.259371  1.697419  13.507797  1.804346  \n",
       "3  0.243548  5.158520   9.989205  1.534308  10.946206  1.715446  \n",
       "4  0.110704  5.336914   9.130732  2.396150  35.118827  1.554082  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# post-comp data from the last file in the run, scaled by cell size\n",
    "dataCompenScaleSizeL_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting RedSEA compensation of file: RNANeg_Tonsil_003\n",
      "0        149224.0\n",
      "1            16.0\n",
      "2            15.0\n",
      "3            18.0\n",
      "4            19.0\n",
      "           ...   \n",
      "13750        18.0\n",
      "13751        10.0\n",
      "13752        24.0\n",
      "13753        13.0\n",
      "13754        11.0\n",
      "Length: 13755, dtype: float64\n",
      "Progress: |██████████████████████████████████████████████████| 100.0% Complete\n"
     ]
    }
   ],
   "source": [
    "# single file run:\n",
    "\n",
    "dataL_full, dataScaleSizeL_full, dataCompenL_full, dataCompenScaleSizeL_full = RunRedSEA(mainPath = mainPath, file = file_single, channel_names_numbers = True, normChannels = normChannels, print_options = \"only_compensated_and_scaled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### For testing / debugging:\n",
    "\n",
    "clusterChannels, countsNoNoise, Segmentation, cellNum, channelNum, data, cellSizes, dataScaleSize = file_reader(mainPath,file_single,channel_names_numbers = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### old stuff\n",
    "\n",
    "def OLD_non_functional_Cell_Edge_Intensities(Segmentation, cellNum, channelNum, countsNoNoise, rowNum, colNum, elementShape = 2, elementSize = 2):    \n",
    "    # now starts the calculation of signals from pixels along the boudnary of cells\n",
    "    MIBIdataNearEdge1 = np.zeros((cellNum+1,channelNum))\n",
    "    newLmod_border = np.pad(Segmentation, pad_width=elementSize, mode='constant', constant_values=0)\n",
    "    # start the boundary region selection and count extraction\n",
    "    \n",
    "    ##### A List of Items\n",
    "    items = list(range(cellNum))\n",
    "    l = len(items)\n",
    "    printProgressBar(0, l, prefix = 'Progress:', suffix = 'Complete', length = 50) # progress bar\n",
    "    #####\n",
    "    \n",
    "    ######pre-calculated shape\n",
    "    if elementShape==1: # square\n",
    "        square=skimage.morphology.square((2*elementSize) + 1)\n",
    "        square_loc=np.where(square==1)\n",
    "    elif elementShape==2: # diamond\n",
    "        diam=skimage.morphology.diamond(elementSize) # create diamond shapte based on elementSize\n",
    "        diam_loc=np.where(diam==1)\n",
    "    else:\n",
    "        print(\"Error elementShape Value not recognized.\")\n",
    "    ############\n",
    "    \n",
    "    for i in range(cellNum):\n",
    "        if i = 0:\n",
    "            continue\n",
    "        [tempRow,tempCol] = np.where(Segmentation==i)\n",
    "        # sequence in row not col, should not affect the code\n",
    "        for j in range(len(tempRow)):\n",
    "            label_in_shape=[] # empty list in case\n",
    "            # make sure not expand outside\n",
    "            #if (elementSize-1<tempRow[j]) and (tempRow[j]<rowNum-elementSize-2) and (elementSize-1<tempCol[j]) and (tempCol[j]<colNum-elementSize-2):\n",
    "            ini_point = [tempRow[j]-elementSize,tempCol[j]-elementSize] # corrected top-left point\n",
    "            if elementShape==1: # square\n",
    "                square_loc_ini_x=[item + ini_point[0] for item in square_loc[0]]\n",
    "                square_loc_ini_y=[item + ini_point[1] for item in square_loc[1]]\n",
    "                \n",
    "                label_in_shape=[Segmentation[square_loc_ini_x[k],square_loc_ini_y[k]] for k in range(len(square_loc_ini_x))]\n",
    "                \n",
    "            elif elementShape==2: # diamond\n",
    "                diam_loc_ini_x=[item + ini_point[0] for item in diam_loc[0]]\n",
    "                diam_loc_ini_y=[item + ini_point[1] for item in diam_loc[1]]\n",
    "                # finish add to ini point\n",
    "            \n",
    "                label_in_shape=[Segmentation[diam_loc_ini_x[k],diam_loc_ini_y[k]] for k in range(len(diam_loc_ini_x))]\n",
    "            is_border_px = len(np.unique(label_in_shape))\n",
    "            \n",
    "            if is_border_px > 1:\n",
    "                MIBIdataNearEdge1[i,:] = MIBIdataNearEdge1[i,:] + countsNoNoise[tempRow[j],tempCol[j],:]\n",
    "        \n",
    "        # Update Progress Bar\n",
    "        printProgressBar(i + 1, l, prefix = 'Progress:', suffix = 'Complete', length = 50)\n",
    "    return MIBIdataNearEdge1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
