{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REDSEA python version BPC For multiple images at a time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further edits of the other steinbock integrated jupyter notebook in this folder. This script is made to ingest entire folder of data at once\r\n",
    "\r\n",
    "Dataset I had been using for CD3 / CD20 compensation: https://zenodo.org/records/8023452\r\n",
    "\r\n",
    "Passed through steinbock to derive .tiffs and masks, then fed into this script\r\n",
    "\r\n",
    "The directory structure required for the script as-written is the one naturally produced by steinbock:\r\n",
    "\r\n",
    "A master directory with two folders: \\img & \\masks - each containing .tiffs with the original images and the DeepCell generated masks, repectively, with matching file names - and 1 .csv file (panel.csv autog generated by steinbock)\r\n",
    "\r\n",
    "WARNING! The script has not been thoroughly tested, but should produce outputs. I still trying to examine it carefully to be absolutely sure that it is doing what I intended! ",
    " WARNING! The script is currently producing an error where the cell-cell matrix loop is not identifying cell borders for some cells (unsure as to why)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package Imports\n",
    "import PIL\n",
    "from PIL import Image, ImageSequence, ImageOps\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage \n",
    "import skimage.measure\n",
    "import skimage.morphology\n",
    "import glob\n",
    "from scipy.io import loadmat\n",
    "import time\n",
    "\n",
    "import tifffile\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Edit these for your run!\n",
    "# file locations\n",
    "mainPath = 'C:\\\\Users\\\\caiello\\\\Desktop\\\\RedSEA practice\\\\practice' # main folder must contain \\img and \\masks folders and a panel.csv file (matching steinbock output)\n",
    "\n",
    "# for multiple images at once:\n",
    "file_list = []\n",
    "for i in os.listdir(mainPath + \"\\\\img\"):\n",
    "    i = i.replace(\".tiff\",\"\")\n",
    "    file_list.append(i)\n",
    "\n",
    "# or set file_name manually\n",
    "file_single = 'RNANeg_Tonsil_003'  #do not include the .tiff file type!\n",
    "\n",
    "#  select which channel to normalize\n",
    "normChannels = [13,18]    # I use numbers here, can switch to names as in your panel file -- if you set \"channel_names_numbers = False\" in the the file_reader call in the next cell \n",
    "\n",
    "# parameters for compensation (change as desired)\n",
    "REDSEAChecker = 1 # 1 means subtract+ reinforce\n",
    "elementShape = 2 # star, 1 == square size\n",
    "elementSize = 2 # star or square extension size\n",
    "\n",
    "\n",
    "# output path\n",
    "pathResults = mainPath + '/intensities' # output location, set as intensities here to match steinbock output\n",
    "try:\n",
    "    os.listdir(pathResults)\n",
    "except:\n",
    "    os.mkdir(pathResults)\n",
    "\n",
    "alt_path = \"\\\\an\\\\alternate\\folder\\\\in\\\\which\\\\to\\\\put\\\\your\\\\non-scaled\\\\and\\\\non-compensated\\\\data\" ## use if you want the non-compensated / non-scaled data, but don't want them crowding the main steinbock intensities folder\n",
    "######### if you use alt_path, manually make the directory in file explorer!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Functions (normally, minimize this cell)\n",
    "# helper function 1\n",
    "def ismember(a, b):\n",
    "    bind = {}\n",
    "    for i, elt in enumerate(b):\n",
    "        if elt not in bind:\n",
    "            bind[elt] = i\n",
    "    return [bind.get(itm, None) for itm in a]  # None can be replaced by any other \"not in b\" value\n",
    "\n",
    "# helper function 2\n",
    "\n",
    "def printProgressBar (iteration, total, prefix = '', suffix = '', decimals = 1, length = 100, fill = '█', printEnd = \"\\r\"):\n",
    "    percent = (\"{0:.\" + str(decimals) + \"f}\").format(100 * (iteration / float(total)))\n",
    "    filledLength = int(length * iteration // total)\n",
    "    bar = fill * filledLength + '-' * (length - filledLength)\n",
    "    print(f'\\r{prefix} |{bar}| {percent}% {suffix}', end = printEnd)\n",
    "    # Print New Line on Complete\n",
    "    if iteration == total: \n",
    "        print()\n",
    "        \n",
    "def file_reader(mainPath,file_name,channel_names_numbers = True):\n",
    "    massDS_path = mainPath + '\\\\panel.csv' # csv file location, need\n",
    "    pathTiff = mainPath + '\\\\img\\\\' + file_name + '.tiff' #  tiff location, links to a single .tiff\n",
    "    pathMat = mainPath + '\\\\masks\\\\' + file_name + '.tiff' # corresponding .tiff's mask\n",
    "        \n",
    "    ####### Read in of files:\n",
    "    ### read in panel.csv\n",
    "    massDS = pd.read_csv(massDS_path) # read the mass csv\n",
    "    if channel_names_numbers == True:\n",
    "        clusterChannels = massDS[massDS['keep'] == 1].reset_index().index.values # only get the label column minus 1 is for zero-indexing (matched channel numbers with Napari)\n",
    "                                                # remove -1 if you want 1-indexing of the channel names\n",
    "    else:\n",
    "        clusterChannels = massDS['name']  # if you want your channel names to be want is used\n",
    "    channelNum = len(clusterChannels) # how many channels\n",
    "    #print(massDS.head())\n",
    "    \n",
    "    #### this part reads in multichannel tiff file\n",
    "    # read in the image and transform into a 'countsNoNoise' matrix\n",
    "    array_list=[]\n",
    "    for channel in clusterChannels:\n",
    "        t=tifffile.imread(pathTiff)[channel]\n",
    "        array_list.append(t)\n",
    "    countsNoNoise=np.stack(array_list,axis=2) # count matrices in the image\n",
    "    \n",
    "    ###### Read in segmentation .tiff\n",
    "        # Define the boundary region\n",
    "        #### these code is just entire translation of redsea matlab v1.0\n",
    "    Segmentation = tifffile.imread(pathMat).astype('int')\n",
    "    cellNum = np.max(Segmentation) # how many labels\n",
    "    stats = skimage.measure.regionprops(Segmentation+1) # get the regional props for all the labels\n",
    "\n",
    "    ### make empty container matrices\n",
    "    data = np.zeros((cellNum + 1,channelNum))\n",
    "    dataScaleSize = np.zeros((cellNum + 1,channelNum))\n",
    "    cellSizes = np.zeros((cellNum + 1,1))\n",
    "    \n",
    "    # this part extract counts data from the whole cell regions, for each individual cells etc\n",
    "    \n",
    "    for i in range(cellNum + 1): # for each cell (label)\n",
    "        label_counts=[countsNoNoise[coord[0],coord[1],:] for coord in stats[i].coords] # all channel count for this cell\n",
    "        data[i,0:channelNum] = np.sum(label_counts, axis=0) #  sum the counts for this cell\n",
    "        dataScaleSize[i,0:channelNum] = np.sum(label_counts, axis=0) / stats[i].area # scaled by size\n",
    "        cellSizes[i] = stats[i].area # cell sizes\n",
    "\n",
    "    return clusterChannels, countsNoNoise, Segmentation, cellNum, channelNum, data, cellSizes, dataScaleSize\n",
    "\n",
    "def cell_cell_matrix(Segmentation, cellNum, REDSEAChecker = REDSEAChecker):\n",
    "    # this block is for computing cell cell matrix\n",
    "    [rowNum, colNum] = Segmentation.shape\n",
    "    cellPairMap = np.zeros(((cellNum + 1),(cellNum + 1))) # cell-cell shared perimeter matrix container\n",
    "    \n",
    "    # start looping the mask and produce the cell-cell contact matrix\n",
    "    for i in range(rowNum):\n",
    "        if i == 0:\n",
    "            a = 0\n",
    "            c = 2\n",
    "        elif i == 999:\n",
    "            a = 1\n",
    "            c = 1\n",
    "        else:\n",
    "            a = 1\n",
    "            c = 2\n",
    "        for j in range(colNum):\n",
    "            if j == 0:\n",
    "                b = 0\n",
    "                d = 2\n",
    "            elif j == 999:\n",
    "                b = 1\n",
    "                d = 1\n",
    "            else:\n",
    "                b = 1\n",
    "                d = 2\n",
    "            tempMatrix = Segmentation[i-a:i+c,j-b:j+d] # the 3x3 window, centered on the point i,j\n",
    "            #print(tempMatrix)\n",
    "            tempFactors = np.unique(tempMatrix).astype('int') #unique\n",
    "            #print(tempFactors)\n",
    "            centerpoint_value = Segmentation[i,j]\n",
    "            #print(centerpoint_value)\n",
    "            for k in tempFactors:\n",
    "                if k != centerpoint_value: # only add to the cellPairMap for the centerpoint pixel -- this prevents multiplicate counting\n",
    "                    #print(\"trigger\")\n",
    "                    cellPairMap[centerpoint_value,k] = cellPairMap[centerpoint_value,k] + 1  \n",
    "        \n",
    "    # converting the cell cell maps to fraction of cell - cell boundary (not of total cell boundary [!?] -- as in boundary with empty space not counted)\n",
    "    cellPairNorm = np.zeros(((cellNum+1),(cellNum+1)))\n",
    "    for i in np.arange(0,len(cellPairMap)):\n",
    "        if np.sum(cellPairMap[i]) > 0:\n",
    "            cellPairNorm[i] = - (cellPairMap[i] / np.sum(cellPairMap[i]))\n",
    "    cellPairNorm = cellPairNorm[1:,1:]\n",
    "    cellPairNorm = cellPairNorm + REDSEAChecker*np.identity(cellNum ) \n",
    "    #display(pd.DataFrame(cellPairMap))\n",
    "    #print(pd.DataFrame(cellPairMap).sum())\n",
    "    return cellPairNorm, rowNum, colNum\n",
    "\n",
    "def Cell_Edge_Intensities(Segmentation, cellNum, channelNum, countsNoNoise, rowNum, colNum, elementShape = 2, elementSize = 2):\n",
    "    # now starts the calculation of signals from pixels along the boudnary of cells\n",
    "    MIBIdataNearEdge1 = np.zeros((cellNum+1,channelNum))\n",
    "    \n",
    "    # start the boundary region selection and count extraction\n",
    "    \n",
    "    ##### A List of Items\n",
    "    items = list(range(cellNum))\n",
    "    l = len(items)\n",
    "    printProgressBar(0, l, prefix = 'Progress:', suffix = 'Complete', length = 50) # progress bar\n",
    "    #####\n",
    "    \n",
    "    ######pre-calculated shape\n",
    "    if elementShape==1: # square\n",
    "        square=skimage.morphology.square(2*elementSize+1)\n",
    "        square_loc=np.where(square==1)\n",
    "    elif elementShape==2: # diamond\n",
    "        diam=skimage.morphology.diamond(elementSize) # create diamond shapte based on elementSize\n",
    "        diam_loc=np.where(diam==1)\n",
    "    else:\n",
    "        print(\"Error elementShape Value not recognized.\")\n",
    "    ############\n",
    "    \n",
    "    for i in range(cellNum):\n",
    "        [tempRow,tempCol] = np.where(Segmentation==i)\n",
    "        # sequence in row not col, should not affect the code\n",
    "        for j in range(len(tempRow)):\n",
    "            label_in_shape=[] # empty list in case\n",
    "            # make sure not expand outside\n",
    "            if (elementSize-1<tempRow[j]) and (tempRow[j]<rowNum-elementSize-2) and (elementSize-1<tempCol[j]) and (tempCol[j]<colNum-elementSize-2):\n",
    "                ini_point = [tempRow[j]-elementSize,tempCol[j]-elementSize] # corrected top-left point\n",
    "            \n",
    "                if elementShape==1: # square\n",
    "                    square_loc_ini_x=[item + ini_point[0] for item in square_loc[0]]\n",
    "                    square_loc_ini_y=[item + ini_point[1] for item in square_loc[1]]\n",
    "                    \n",
    "                    label_in_shape=[Segmentation[square_loc_ini_x[k],square_loc_ini_y[k]] for k in range(len(square_loc_ini_x))]\n",
    "                    \n",
    "                elif elementShape==2: # diamond\n",
    "                    diam_loc_ini_x=[item + ini_point[0] for item in diam_loc[0]]\n",
    "                    diam_loc_ini_y=[item + ini_point[1] for item in diam_loc[1]]\n",
    "                    # finish add to ini point\n",
    "                \n",
    "                    label_in_shape=[Segmentation[diam_loc_ini_x[k],diam_loc_ini_y[k]] for k in range(len(diam_loc_ini_x))]\n",
    "            is_border_px = len(np.unique(label_in_shape))\n",
    "            \n",
    "            if is_border_px > 1:\n",
    "                MIBIdataNearEdge1[i,:] = MIBIdataNearEdge1[i,:] + countsNoNoise[tempRow[j],tempCol[j],:]\n",
    "        \n",
    "        # Update Progress Bar\n",
    "        printProgressBar(i + 1, l, prefix = 'Progress:', suffix = 'Complete', length = 50)\n",
    "    return MIBIdataNearEdge1\n",
    "\n",
    "def CalculateREDSEA(MIBIdataNearEdge1, cellPairNorm, data, channelNormIdentity, cellNum, dataScaleSize, cellSizes):    \n",
    "    MIBIdataNorm2 = np.transpose(np.dot(np.transpose(MIBIdataNearEdge1[1:,:]),cellPairNorm))\n",
    "    #this is boundary signal subtracted by cell neighbor boundary\n",
    "    MIBIdataNorm2 = MIBIdataNorm2 + data[1:,:] # reinforce onto the whole cell signal (original signal)\n",
    "    \n",
    "    MIBIdataNorm2[MIBIdataNorm2<0] = 0 # clear out the negative ones\n",
    "    # flip the channelNormIdentity for calculation\n",
    "    rev_channelNormIdentity=np.ones_like(channelNormIdentity)-channelNormIdentity\n",
    "    # composite the normalized channels with non-normalized channels\n",
    "    # MIBIdataNorm2 is the matrix to return\n",
    "    MIBIdataNorm2 = data[1:,:] * np.transpose(np.tile(rev_channelNormIdentity,(1,cellNum))) + MIBIdataNorm2 * np.transpose(np.tile(channelNormIdentity,(1,cellNum)))\n",
    "    \n",
    "    # the function should return 4 variables\n",
    "    dataCells = data[1:,:]\n",
    "    dataScaleSizeCells = dataScaleSize[1:,:]\n",
    "    dataCompenCells = MIBIdataNorm2\n",
    "    dataCompenScaleSizeCells = MIBIdataNorm2 / cellSizes[1:,:]\n",
    "\n",
    "    return dataCells, dataScaleSizeCells, dataCompenCells, dataCompenScaleSizeCells\n",
    "\n",
    "def data_matrix_with_label_and_cellsizes(data_in, cellNum, cellSizes, clusterChannels):\n",
    "    ### in a separate funcito because this data is not likely to be wanted. still it can be accessed:\n",
    "    labelVec = [i for i in np.arange(1,cellNum + 1,1)]\n",
    "    cellSizesVec_flat = [item for sublist in cellSizes[1:,:] for item in sublist] # flat the list\n",
    "    dataL = pd.DataFrame({'Object':labelVec, 'cell_size':cellSizesVec_flat})\n",
    "    dataCells_df=pd.DataFrame(data_in)\n",
    "    dataCells_df.columns = clusterChannels\n",
    "    data_out = pd.concat((dataL,dataCells_df),axis=1)\n",
    "    return data_out\n",
    "\n",
    "def Outputter(data_in, file_name, pathResults = pathResults):\n",
    "    data_in.to_csv(pathResults + '\\\\' + file_name + \".csv\", index = False)\n",
    "\n",
    "def RunRedSEA(mainPath, file, channel_names_numbers = True, pathResults = pathResults, alt_path = pathResults, normChannels = normChannels, print_options = \"only_compensated_and_scaled\"):\n",
    "    if print_options not in ['only_compensated_and_scaled','only_scaled','all']:\n",
    "        raise(\"Error: print_options not one of the following: 'only_compensated_and_scaled', 'only_scaled', or 'all'!\") \n",
    "    if type(file) == list:\n",
    "        for ii in file:\n",
    "            file_name = ii\n",
    "            print(\"Starting RedSEA compensation of file: \" + file_name)\n",
    "            clusterChannels, countsNoNoise, Segmentation, cellNum, channelNum, data, cellSizes, dataScaleSize = file_reader(mainPath, ii, channel_names_numbers = channel_names_numbers)\n",
    "            normChannelsInds = ismember(normChannels,clusterChannels)\n",
    "            channelNormIdentity = np.zeros((len(clusterChannels),1))\n",
    "            # make a flag for compensation\n",
    "            for i in range(len(normChannelsInds)):\n",
    "                    channelNormIdentity[normChannelsInds[i]] = 1 \n",
    "            # print(\"cellNum for \" + file_name + \" \" + str(cellNum))\n",
    "            cellPairNorm, rowNum, colNum = cell_cell_matrix(Segmentation = Segmentation, REDSEAChecker = REDSEAChecker, cellNum = cellNum)\n",
    "            MIBIdataNearEdge1 = Cell_Edge_Intensities(Segmentation, countsNoNoise = countsNoNoise, cellNum = cellNum, channelNum = channelNum, rowNum = rowNum, colNum = colNum, elementShape = 2, elementSize = 2)\n",
    "            dataCells, dataScaleSizeCells, dataCompenCells, dataCompenScaleSizeCells = CalculateREDSEA(MIBIdataNearEdge1 = MIBIdataNearEdge1, cellPairNorm = cellPairNorm, data = data, channelNormIdentity = channelNormIdentity, cellNum = cellNum, dataScaleSize = dataScaleSize, cellSizes = cellSizes)\n",
    "            dataL_full = data_matrix_with_label_and_cellsizes(dataCells, cellNum = cellNum, cellSizes = cellSizes, clusterChannels = clusterChannels)\n",
    "            dataScaleSizeL_full = data_matrix_with_label_and_cellsizes(dataScaleSizeCells, cellNum = cellNum, cellSizes = cellSizes, clusterChannels = clusterChannels)\n",
    "            dataCompenL_full = data_matrix_with_label_and_cellsizes(dataCompenCells, cellNum = cellNum, cellSizes = cellSizes, clusterChannels = clusterChannels)\n",
    "            dataCompenScaleSizeL_full = data_matrix_with_label_and_cellsizes(dataCompenScaleSizeCells, cellNum = cellNum, cellSizes = cellSizes, clusterChannels = clusterChannels)\n",
    "            if print_options == \"only_compensated_and_scaled\":\n",
    "                Outputter(dataCompenScaleSizeL_full, file_name = file_name)\n",
    "            elif print_options == \"only_scaled\":\n",
    "                Outputter(dataCompenScaleSizeL_full, file_name = file_name)\n",
    "                Outputter(dataScaleSizeL_full, file_name = file_name + \"_pre_REDSEA.csv\", pathResults = alt_path)\n",
    "            elif print_options == \"all\":\n",
    "                Outputter(dataL_full, file_name = file_name + \"_pre_REDSEA_unscaled.csv\")\n",
    "                Outputter(dataScaleSizeL_full, file_name = file_name + \"_pre_REDSEA_scaled.csv\")\n",
    "                Outputter(dataCompenL_full, file_name = file_name + \"_post_REDSEA_unscaled.csv\")\n",
    "                Outputter(dataCompenScaleSizeL_full, file_name = file_name)\n",
    "    elif type(file) == str:\n",
    "        file_name = file\n",
    "        print(\"Starting RedSEA compensation of file: \" + file_name)\n",
    "        clusterChannels, countsNoNoise, Segmentation, cellNum, channelNum, data, cellSizes, dataScaleSize = file_reader(mainPath, file_name, channel_names_numbers = channel_names_numbers)\n",
    "        normChannelsInds = ismember(normChannels,clusterChannels)\n",
    "        channelNormIdentity = np.zeros((len(clusterChannels),1))\n",
    "        # make a flag for compensation\n",
    "        for i in range(len(normChannelsInds)):\n",
    "                channelNormIdentity[normChannelsInds[i]] = 1 \n",
    "        # print(\"cellNum for \" + file_name + \" \" + str(cellNum))\n",
    "        cellPairNorm, rowNum, colNum = cell_cell_matrix(Segmentation = Segmentation, REDSEAChecker = REDSEAChecker, cellNum = cellNum)\n",
    "        MIBIdataNearEdge1 = Cell_Edge_Intensities(Segmentation, countsNoNoise = countsNoNoise, cellNum = cellNum, channelNum = channelNum, rowNum = rowNum, colNum = colNum, elementShape = 2, elementSize = 2)\n",
    "        dataCells, dataScaleSizeCells, dataCompenCells, dataCompenScaleSizeCells = CalculateREDSEA(MIBIdataNearEdge1 = MIBIdataNearEdge1, cellPairNorm = cellPairNorm, data = data, channelNormIdentity = channelNormIdentity, cellNum = cellNum, dataScaleSize = dataScaleSize, cellSizes = cellSizes)\n",
    "        dataL_full = data_matrix_with_label_and_cellsizes(dataCells, cellNum = cellNum, cellSizes = cellSizes, clusterChannels = clusterChannels)\n",
    "        dataScaleSizeL_full = data_matrix_with_label_and_cellsizes(dataScaleSizeCells, cellNum = cellNum, cellSizes = cellSizes, clusterChannels = clusterChannels)\n",
    "        dataCompenL_full = data_matrix_with_label_and_cellsizes(dataCompenCells, cellNum = cellNum, cellSizes = cellSizes, clusterChannels = clusterChannels)\n",
    "        dataCompenScaleSizeL_full = data_matrix_with_label_and_cellsizes(dataCompenScaleSizeCells, cellNum = cellNum, cellSizes = cellSizes, clusterChannels = clusterChannels)\n",
    "        if print_options == \"only_compensated_and_scaled\":\n",
    "            Outputter(dataCompenScaleSizeL_full, file_name = file_name)\n",
    "        elif print_options == \"only_scaled\":\n",
    "            Outputter(dataCompenScaleSizeL_full, file_name = file_name)\n",
    "            Outputter(dataScaleSizeL_full, file_name = file_name + \"_pre_REDSEA.csv\", pathResults = alt_path)\n",
    "        elif print_options == \"all\":\n",
    "            Outputter(dataL_full, file_name = file_name + \"_pre_REDSEA_unscaled.csv\")\n",
    "            Outputter(dataScaleSizeL_full, file_name = file_name + \"_pre_REDSEA_scaled.csv\")\n",
    "            Outputter(dataCompenL_full, file_name = file_name + \"_post_REDSEA_unscaled.csv\")\n",
    "            Outputter(dataCompenScaleSizeL_full, file_name = file_name)\n",
    "    return dataL_full, dataScaleSizeL_full, dataCompenL_full, dataCompenScaleSizeL_full # these are the files of only the last file, if running multiple files at once\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting RedSEA compensation of file: RNANeg_Tonsil_001\n",
      "Progress: |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Starting RedSEA compensation of file: RNANeg_Tonsil_002\n",
      "Progress: |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Starting RedSEA compensation of file: RNANeg_Tonsil_003\n",
      "Progress: |██████████████████████████████████████████████████| 100.0% Complete\n",
      "Starting RedSEA compensation of file: RNANeg_Tonsil_004\n",
      "Progress: |██████████████████████████████████████████████████| 100.0% Complete\n"
     ]
    }
   ],
   "source": [
    "# Whole folder run (this one had 4 files in it):\n",
    "dataL_full, dataScaleSizeL_full, dataCompenL_full, dataCompenScaleSizeL_full = RunRedSEA(mainPath = mainPath, file = file_list, channel_names_numbers = True, normChannels = normChannels, print_options = \"only_scaled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Object</th>\n",
       "      <th>cell_size</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>5.647098</td>\n",
       "      <td>3.013256</td>\n",
       "      <td>1.318903</td>\n",
       "      <td>1.036586</td>\n",
       "      <td>1.262176</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.101948</td>\n",
       "      <td>...</td>\n",
       "      <td>0.351574</td>\n",
       "      <td>2.039562</td>\n",
       "      <td>4.189841</td>\n",
       "      <td>0.351362</td>\n",
       "      <td>0.385892</td>\n",
       "      <td>12.605571</td>\n",
       "      <td>18.170195</td>\n",
       "      <td>4.810619</td>\n",
       "      <td>27.770319</td>\n",
       "      <td>1.949942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.467000</td>\n",
       "      <td>0.922300</td>\n",
       "      <td>1.235178</td>\n",
       "      <td>0.218416</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>1.218475</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.711730</td>\n",
       "      <td>0.928775</td>\n",
       "      <td>0.387283</td>\n",
       "      <td>0.252729</td>\n",
       "      <td>6.553608</td>\n",
       "      <td>9.611255</td>\n",
       "      <td>1.744451</td>\n",
       "      <td>28.690329</td>\n",
       "      <td>1.282992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>2.074444</td>\n",
       "      <td>1.400868</td>\n",
       "      <td>0.970991</td>\n",
       "      <td>0.214524</td>\n",
       "      <td>1.288590</td>\n",
       "      <td>0.344656</td>\n",
       "      <td>0.448292</td>\n",
       "      <td>...</td>\n",
       "      <td>0.207362</td>\n",
       "      <td>2.548671</td>\n",
       "      <td>1.080995</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.230224</td>\n",
       "      <td>5.562967</td>\n",
       "      <td>7.117647</td>\n",
       "      <td>1.381895</td>\n",
       "      <td>22.161097</td>\n",
       "      <td>1.549177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>1.232233</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.644276</td>\n",
       "      <td>0.413830</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.558378</td>\n",
       "      <td>...</td>\n",
       "      <td>0.519149</td>\n",
       "      <td>1.976839</td>\n",
       "      <td>0.455801</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>3.502497</td>\n",
       "      <td>5.479109</td>\n",
       "      <td>1.653704</td>\n",
       "      <td>40.382545</td>\n",
       "      <td>3.176192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.105961</td>\n",
       "      <td>1.196886</td>\n",
       "      <td>0.993774</td>\n",
       "      <td>0.323342</td>\n",
       "      <td>1.038583</td>\n",
       "      <td>0.144026</td>\n",
       "      <td>1.982418</td>\n",
       "      <td>...</td>\n",
       "      <td>0.396339</td>\n",
       "      <td>2.125142</td>\n",
       "      <td>1.058890</td>\n",
       "      <td>0.243160</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>7.997893</td>\n",
       "      <td>12.763613</td>\n",
       "      <td>1.115945</td>\n",
       "      <td>8.551426</td>\n",
       "      <td>1.737276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Object  cell_size         0         1         2         3         4  \\\n",
       "0       1       12.0  0.083333  5.647098  3.013256  1.318903  1.036586   \n",
       "1       2       12.0  0.000000  1.467000  0.922300  1.235178  0.218416   \n",
       "2       3       11.0  0.090909  2.074444  1.400868  0.970991  0.214524   \n",
       "3       4        8.0  0.000000  0.125000  1.232233  0.250000  0.644276   \n",
       "4       5       15.0  0.000000  2.105961  1.196886  0.993774  0.323342   \n",
       "\n",
       "          5         6         7  ...        16        17        18        19  \\\n",
       "0  1.262176  0.000000  2.101948  ...  0.351574  2.039562  4.189841  0.351362   \n",
       "1  0.416667  0.083333  1.218475  ...  0.000000  1.711730  0.928775  0.387283   \n",
       "2  1.288590  0.344656  0.448292  ...  0.207362  2.548671  1.080995  0.000000   \n",
       "3  0.413830  0.000000  0.558378  ...  0.519149  1.976839  0.455801  0.250000   \n",
       "4  1.038583  0.144026  1.982418  ...  0.396339  2.125142  1.058890  0.243160   \n",
       "\n",
       "         20         21         22        23         24        25  \n",
       "0  0.385892  12.605571  18.170195  4.810619  27.770319  1.949942  \n",
       "1  0.252729   6.553608   9.611255  1.744451  28.690329  1.282992  \n",
       "2  0.230224   5.562967   7.117647  1.381895  22.161097  1.549177  \n",
       "3  0.250000   3.502497   5.479109  1.653704  40.382545  3.176192  \n",
       "4  0.066667   7.997893  12.763613  1.115945   8.551426  1.737276  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pre-comp data from the last file in the run, scaled by cell size\n",
    "dataScaleSizeL_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Object</th>\n",
       "      <th>cell_size</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>5.647098</td>\n",
       "      <td>3.013256</td>\n",
       "      <td>1.318903</td>\n",
       "      <td>1.036586</td>\n",
       "      <td>1.262176</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.101949</td>\n",
       "      <td>...</td>\n",
       "      <td>0.351574</td>\n",
       "      <td>2.039562</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.351362</td>\n",
       "      <td>0.385892</td>\n",
       "      <td>12.605570</td>\n",
       "      <td>18.170195</td>\n",
       "      <td>4.810619</td>\n",
       "      <td>27.770320</td>\n",
       "      <td>1.949942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.467000</td>\n",
       "      <td>0.922300</td>\n",
       "      <td>1.235178</td>\n",
       "      <td>0.218416</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>1.218475</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.711730</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.387283</td>\n",
       "      <td>0.252729</td>\n",
       "      <td>6.553608</td>\n",
       "      <td>9.611255</td>\n",
       "      <td>1.744451</td>\n",
       "      <td>28.690328</td>\n",
       "      <td>1.282992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>2.074444</td>\n",
       "      <td>1.400868</td>\n",
       "      <td>0.970991</td>\n",
       "      <td>0.214524</td>\n",
       "      <td>1.288590</td>\n",
       "      <td>0.344656</td>\n",
       "      <td>0.448292</td>\n",
       "      <td>...</td>\n",
       "      <td>0.207362</td>\n",
       "      <td>2.548671</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.230224</td>\n",
       "      <td>5.562967</td>\n",
       "      <td>7.117647</td>\n",
       "      <td>1.381895</td>\n",
       "      <td>22.161097</td>\n",
       "      <td>1.549177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>1.232233</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.644276</td>\n",
       "      <td>0.413830</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.558378</td>\n",
       "      <td>...</td>\n",
       "      <td>0.519149</td>\n",
       "      <td>1.976839</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>3.502497</td>\n",
       "      <td>5.479109</td>\n",
       "      <td>1.653704</td>\n",
       "      <td>40.382545</td>\n",
       "      <td>3.176192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.105961</td>\n",
       "      <td>1.196886</td>\n",
       "      <td>0.993774</td>\n",
       "      <td>0.323342</td>\n",
       "      <td>1.038583</td>\n",
       "      <td>0.144026</td>\n",
       "      <td>1.982418</td>\n",
       "      <td>...</td>\n",
       "      <td>0.396339</td>\n",
       "      <td>2.125142</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.243160</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>7.997893</td>\n",
       "      <td>12.763613</td>\n",
       "      <td>1.115945</td>\n",
       "      <td>8.551426</td>\n",
       "      <td>1.737276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Object  cell_size         0         1         2         3         4  \\\n",
       "0       1       12.0  0.083333  5.647098  3.013256  1.318903  1.036586   \n",
       "1       2       12.0  0.000000  1.467000  0.922300  1.235178  0.218416   \n",
       "2       3       11.0  0.090909  2.074444  1.400868  0.970991  0.214524   \n",
       "3       4        8.0  0.000000  0.125000  1.232233  0.250000  0.644276   \n",
       "4       5       15.0  0.000000  2.105961  1.196886  0.993774  0.323342   \n",
       "\n",
       "          5         6         7  ...        16        17   18        19  \\\n",
       "0  1.262176  0.000000  2.101949  ...  0.351574  2.039562  0.0  0.351362   \n",
       "1  0.416667  0.083333  1.218475  ...  0.000000  1.711730  0.0  0.387283   \n",
       "2  1.288590  0.344656  0.448292  ...  0.207362  2.548671  0.0  0.000000   \n",
       "3  0.413830  0.000000  0.558378  ...  0.519149  1.976839  0.0  0.250000   \n",
       "4  1.038583  0.144026  1.982418  ...  0.396339  2.125142  0.0  0.243160   \n",
       "\n",
       "         20         21         22        23         24        25  \n",
       "0  0.385892  12.605570  18.170195  4.810619  27.770320  1.949942  \n",
       "1  0.252729   6.553608   9.611255  1.744451  28.690328  1.282992  \n",
       "2  0.230224   5.562967   7.117647  1.381895  22.161097  1.549177  \n",
       "3  0.250000   3.502497   5.479109  1.653704  40.382545  3.176192  \n",
       "4  0.066667   7.997893  12.763613  1.115945   8.551426  1.737276  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# post-comp data from the last file in the run, scaled by cell size\n",
    "dataCompenScaleSizeL_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting RedSEA compensation of file: RNANeg_Tonsil_003\n",
      "Progress: |██████████████████████████████████████████████████| 100.0% Complete\n"
     ]
    }
   ],
   "source": [
    "# single file run:\n",
    "\n",
    "dataL_full, dataScaleSizeL_full, dataCompenL_full, dataCompenScaleSizeL_full = RunRedSEA(mainPath = mainPath, file = file_single, channel_names_numbers = True, normChannels = normChannels, print_options = \"only_compensated_and_scaled\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
